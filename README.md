# crawl_applicant
파이썬을 활용하여, 구글 폼으로 받은 지원서 중 면접 대상자 지원서만 크롤링하여 offlie면접, online면접 데이터로 나누기

## stack
python 3.8.0

et-xmlfile==1.0.1
jdcal==1.4.1
openpyxl==3.0.3



## 사용안내
data 폴더 안에 아래 2가지 데이터를 준비합니다.
1. application.csv: 구글폼으로 받은 지원자들의 서류를 구글 폼 내에서 csv로 다운받아, application.csv라는 이름으로 수정합니다.
2. timetable.xlsx: 구글 공유 문서에서 배포용이 아닌 면접 타임테이블을 우클릭하여 xlsx 파일로 다운받아, timetable.xlsx라는 이름으로 수정합니다.   
   
이후 해당 repo의 make.py 파일을 실행하여, data 폴더 안에 생성되는 online_data, offline_data 파일을 확인한다.   
* 지원자들의 개인정보 내용이기 때문에 data 폴더는 비워두었습니다.

## 왜 만들었나
사실 별 이유는 없다...   
최근 파이썬 코딩을 많이 안했던 것 같아서 뭐라도 해보고 싶었는데 마침 멋사 신입기수 면접에 있어서 지원자들의 지원서를 일일이 찾기에 귀찮을 것 같아서 만들어봤다.   
물론 면접 대상자를 통틀어도 100명이 안되기 때문에 이렇게 코드로 분류시키는 것이 오히려 물리적 시간에 있어서는 손해일지도 모른다.   
현업이었다면 아래와 같은 요소를 고려했을 것이다.   
1. 분류할 case가 많거나, 대상자가 많은지?
2. 대상자가 적더라도, 앞으로 꾸준하게 발생할 case인지?   
   
만약 위와 같은 요소들을 어느정도 충족한다면, 코드로써 분류자동화 하는 것이 시간적 단축을 가져올 것이다.   


## 후기
과거에 파이썬으로 엑셀을 다루는 것은 현업에서 진행해봐서 크게 어려움은 없었다.   
오히려 최근 파이썬 언어에 대한 클린코드에 대해 공부하면서 학습한 docstring과 annotation을 최대한 작성해보았다.   
잘 작성했다라고는 못하겠지만, 사용해본 것에 의의를 두자.   
실제로 코드 구현 초기에, 각 클래스와 함수를 세팅하고 docstring과 annotation만 표시해가면서 구상을 했는데 이부분은 확실히 코드구현에 있어서 좋았다.   
구현을 하면서 조금씩 변경된 점도 있지만, 그래도 어느정도의 틀을 가져가면서 매끄럽게 코드구현이 진행될 수 있었던 것 같다.


> ### Repo 안내
> 해당 repository내의 모든 내용에 대한 권한은 문범우에게 있습니다.   
> 관련 내용에 대한 무단도용 및 무단참조는 허가하지 않습니다.   
> E: doorbw@outlook.com